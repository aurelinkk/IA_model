# -*- coding: utf-8 -*-
"""GARBAGE_detr_implementation_Ameni.ipynb

Automatically generated by Colaboratory.

"""

import sys
print(sys.path)

import torch
import supervision as sv
import transformers
import pytorch_lightning
import os
import random
import cv2
import numpy as np
import timm
import matplotlib.pyplot as plt


import torch
torch.__version__

import supervision
import transformers

supervision.__version__ , transformers.__version__

import pytorch_lightning
print(pytorch_lightning.__version__)

"""## Create COCO data loaders

### About dataset:

#### number of classes : 15 -["accartocciamento_fogliare", "vl_black_rot" "vg_black_rot", "vl_grey_mould", "vg_grey_mould ,"carie_bianca_grappolo", "vines_leaf" ,"vines_grape", "malattia_esca", "vl_powdery_mildew" , "vg_powdery_mildew" ,"oidio_tralci" ,"vl_downy_mildew", "vg_downy_mildew" , "red_blotch_foglia" , "virosi_pinot_grigio"]
"""

import os
import torchvision

dataset_root = 'C:\\Users\\aurel\\Documents\\Stage\\code\\Garbage_dataset\\GARBAGE\\'

images_folder = ''  # Subfolder containing images

ANNOTATION_FILE_NAME = "_annotations.coco.json"
TRAIN_DIRECTORY = os.path.join(dataset_root, "train", images_folder)
VAL_DIRECTORY = os.path.join(dataset_root, "valid", images_folder)
TEST_DIRECTORY = os.path.join(dataset_root, "test", images_folder)

print(dataset_root)
print(TRAIN_DIRECTORY)
print(VAL_DIRECTORY)

import torch
from transformers import DetrImageProcessor
image_processor = DetrImageProcessor.from_pretrained("facebook/detr-resnet-50")


import torchvision
class CocoDetection(torchvision.datasets.CocoDetection):
    def __init__(
        self,
        image_directory_path: str,
        annotation_directory_path: str,
        image_processor,
        train: bool = True
    ):
        annotation_file_path = os.path.join(annotation_directory_path, ANNOTATION_FILE_NAME)
        super(CocoDetection, self).__init__(image_directory_path, annotation_file_path)
        self.image_processor = image_processor

    def __getitem__(self, idx):
        images, annotations = super(CocoDetection, self).__getitem__(idx)
        image_id = self.ids[idx]
        annotations = {'image_id': image_id, 'annotations': annotations}
        encoding = self.image_processor(images=images, annotations=annotations, return_tensors="pt")
        pixel_values = encoding["pixel_values"].squeeze()
        target = encoding["labels"][0]

        return pixel_values, target
    
TRAIN_DATASET = CocoDetection(image_directory_path=TRAIN_DIRECTORY, annotation_directory_path=dataset_root + "train", image_processor=image_processor, train=True)
VAL_DATASET = CocoDetection(image_directory_path=VAL_DIRECTORY, annotation_directory_path=dataset_root + "valid", image_processor=image_processor, train=False)
TEST_DATASET = CocoDetection(image_directory_path=TEST_DIRECTORY, annotation_directory_path=dataset_root + "test", image_processor=image_processor, train=False)
print("Number of training examples:", len(TRAIN_DATASET))
print("Number of validation examples:", len(VAL_DATASET))
print("Number of test examples: ", len(TEST_DATASET))


# select random image
image_ids = TRAIN_DATASET.coco.getImgIds()
image_id = random.choice(image_ids)
image_info = TRAIN_DATASET.coco.loadImgs(image_id)[0]
print('Image #{}: {}'.format(image_id, image_info['file_name']))  # Print image file name

# Construct the correct image file path
image_path = os.path.join(TRAIN_DATASET.root, image_info['file_name'])

# Check if the image file exists
if os.path.exists(image_path):
    # Load image
    image = cv2.imread(image_path)

    # Load annotations
    annotations = TRAIN_DATASET.coco.imgToAnns[image_id]
    
    print("\nAnnotations : \n")
    print(annotations)
    
    # Annotate
    detections = sv.Detections.from_coco_annotations(coco_annotation=annotations)
    
    print("\nDetections : \n")
    print(detections)

    # Create label dictionary
    categories = TRAIN_DATASET.coco.cats
    id2label = {k: v['name'] for k,v in categories.items()}
    
    # Extract labels
    labels = [f"{id2label[class_id]}" for _, _, class_id, _ in detections]
    
    print("\n Labels : \n")
    print(labels)

    # Create box annotator
    box_annotator = sv.BoxAnnotator()

    # Annotate the image
    frame = box_annotator.annotate(scene=image, detections=detections, labels=labels)

    # Display the annotated image with Matplotlib
    sv.show_frame_in_notebook(image, (8, 8))

    image_name = image_path.split("/")[-1]
    
    path_image_save = "./results/" + image_name
    

    #cv2.imwrite(path_image_save, frame)
    
    #print("Chemin de l'image créée:", path_image_save)
    #cv2.imwrite()
    
else:
    print("Image file does not exist:", image_path)
    # Handle the case where the image file does not exist
    
    
    
from torch.utils.data import DataLoader

def collate_fn(batch):
    pixel_values = [item[0] for item in batch]
    encoding = image_processor.pad(pixel_values, return_tensors="pt")
    labels = [item[1] for item in batch]
    return {
        'pixel_values': encoding['pixel_values'],
        'pixel_mask': encoding['pixel_mask'],
        'labels': labels
    }

TRAIN_DATALOADER = DataLoader(dataset=TRAIN_DATASET, collate_fn=collate_fn, batch_size=4, shuffle=True)
VAL_DATALOADER = DataLoader(dataset=VAL_DATASET, collate_fn=collate_fn, batch_size=4)
TEST_DATALOADER = DataLoader(dataset=TEST_DATASET, collate_fn=collate_fn, batch_size=4)


import pytorch_lightning as pl
from transformers import DetrForObjectDetection
import torch


class Detr(pl.LightningModule):

    def __init__(self, lr, lr_backbone, weight_decay, rank, alpha):
        super().__init__()
        self.model = DetrForObjectDetection.from_pretrained(
            pretrained_model_name_or_path="facebook/detr-resnet-50",
            num_labels=len(id2label),
            ignore_mismatched_sizes=True
        )

        self.lr = lr
        self.lr_backbone = lr_backbone
        self.weight_decay = weight_decay
                
        
    def init_linear_class(self, rank, alpha):
        self.linear_class = LinearWithLoRA(self.model.class_embed, rank, alpha)
        
    def init_linear_bbox(self, rank, alpha):
        self.linear_bbox = LinearWithLoRA(self.model.bbox_embed, rank, alpha)

    def forward(self, pixel_values, pixel_mask):
        return self.model(pixel_values=pixel_values, pixel_mask=pixel_mask)

    def common_step(self, batch, batch_idx):
        pixel_values = batch["pixel_values"]
        pixel_mask = batch["pixel_mask"]
        labels = [{k: v.to(self.device) for k, v in t.items()} for t in batch["labels"]]

        outputs = self.model(pixel_values=pixel_values, pixel_mask=pixel_mask, labels=labels)

        loss = outputs.loss
        loss_dict = outputs.loss_dict

        return loss, loss_dict

    def training_step(self, batch, batch_idx):
        loss, loss_dict = self.common_step(batch, batch_idx)
        # logs metrics for each training_step, and the average across the epoch
        self.log("training_loss", loss)
        for k,v in loss_dict.items():
            self.log("train_" + k, v.item())

        return loss

    def validation_step(self, batch, batch_idx):
        loss, loss_dict = self.common_step(batch, batch_idx)
        self.log("validation/loss", loss)
        for k, v in loss_dict.items():
            self.log("validation_" + k, v.item())

        return loss

    def configure_optimizers(self):
        # DETR authors decided to use different learning rate for backbone
        # you can learn more about it here:
        # - https://github.com/facebookresearch/detr/blob/3af9fa878e73b6894ce3596450a8d9b89d918ca9/main.py#L22-L23
        # - https://github.com/facebookresearch/detr/blob/3af9fa878e73b6894ce3596450a8d9b89d918ca9/main.py#L131-L139
        param_dicts = [
            {
                "params": [p for n, p in self.named_parameters() if "backbone" not in n and p.requires_grad]},
            {
                "params": [p for n, p in self.named_parameters() if "backbone" in n and p.requires_grad],
                "lr": self.lr_backbone,
            },
        ]
        return torch.optim.AdamW(param_dicts, lr=self.lr, weight_decay=self.weight_decay)

    def train_dataloader(self):
        return TRAIN_DATALOADER

    def val_dataloader(self):
        return VAL_DATALOADER
    

import torch

print(torch.cuda.is_available())


class LoRALayer(torch.nn.Module):
    def __init__(self, in_dim, out_dim, rank, alpha):
        super().__init__()
        std_dev = 1 / torch.sqrt(torch.tensor(rank).float())
        self.W_a = torch.nn.Parameter(torch.randn(in_dim, rank) * std_dev)
        self.W_b = torch.nn.Parameter(torch.zeros(rank, out_dim))
        self.alpha = alpha

    def forward(self, x):
        x = self.alpha * (x @ self.W_a @ self.W_b)
        return x


class LinearWithLoRA(torch.nn.Module):
    def __init__(self, linear, rank, alpha):
        super().__init__()
        self.linear = linear
        self.lora = LoRALayer(
            linear.in_features, linear.out_features, rank, alpha
        )

    def forward(self, x):
        return self.linear(x) + self.lora(x)
    
################################################################################################################################################################################

lora_r = 8
lora_alpha = 16

print("test")

model = Detr(lr=1e-4, lr_backbone=1e-5, weight_decay=1e-4, rank=lora_r, alpha=lora_alpha)

for param in model.parameters():
    param.requires_grad = False

print("\nEncoder : \n")


lora_r = 8
lora_alpha = 16
lora_dropout = 0.05
lora_query = True
lora_key = False
lora_value = True
lora_projection = False
lora_mlp = False
lora_head = False

from functools import partial

assign_lora = partial(LinearWithLoRA, rank=lora_r, alpha=lora_alpha)

# Add Lora Layers to encoder 
for layer in model.model.model.encoder.layers : 
    
    if lora_query : 
        layer.self_attn.q_proj = assign_lora(layer.self_attn.q_proj)
    
    if lora_key :
        
        layer.self_attn.k_proj = assign_lora(layer.self_attn.k_proj)
        
    if lora_value : 
        
        layer.self_attn.v_proj = assign_lora(layer.self_attn.v_proj)
        
    if  lora_projection : 
        
        layer.self_attn.out_proj = assign_lora(layer.self_attn.out_proj)
        
    if lora_mlp :
        
        layer.activation_fn.fc1 = assign_lora(layer.activation_fn.fc1)
        layer.activation_fn.fc2 = assign_lora(layer.activation_fn.fc2)

if lora_head : 
    
    model.model.model.class_labels_classifier = assign_lora(model.model.model.class_labels_classifier) 

print("\nModèle après changement des couches : \n")

print(model)

def print_trainable_parameters(model):
    trainable_params = 0
    all_param = 0
    for _, param in model.named_parameters():
        all_param += param.numel()
        if param.requires_grad:
            trainable_params += param.numel()
    print(
        f"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}"
    )

print_trainable_parameters(model)

print("\n Decoder : \n")

decodeur = model.model.model.decoder


print(iter(TRAIN_DATALOADER).__dict__)
batch = next(iter(TRAIN_DATALOADER))


outputs = model(pixel_values=batch['pixel_values'], pixel_mask=batch['pixel_mask'])

#print(outputs)


import torch
torch.cuda.empty_cache()
print(torch.cuda.is_available())


from pytorch_lightning import Trainer

# settings
MAX_EPOCHS = 200

trainer = Trainer(devices=1, accelerator="gpu", max_epochs=MAX_EPOCHS, gradient_clip_val=0.1, accumulate_grad_batches=8, log_every_n_steps=1)

trainer.fit(model)